- [Characterization of regional differences in resting-state fMRI with a data-driven network model of brain dynamics | Science Advances](https://www.science.org/doi/10.1126/sciadv.abq7547)
- #[[Viktor Jirsa]]
- ![sciadv.abq7547.pdf](../assets/sciadv.abq7547_1726021778082_0.pdf)
-
- ## Abstract
	- 基于模型的全脑动力学数据分析将观察到的数据与神经群体网络中的模型参数联系起来。最近，研究重点是模型参数的区域方差的作用。然而，此类分析必然取决于预选神经群体模型的属性。我们引入了一种方法，可以**根据功能数据推断代表区域动态的神经群体模型以及区域和被试特定的参数**，同时尊重已知的网络结构。我们将该方法应用于人体静息态功能磁共振成像。我们发现**潜在的动态可以描述为围绕单个固定点的噪声波动**。该方法可靠地发现了三个在动力学中具有清晰和独特作用的区域参数，其中一个与基因表达空间图的第一主成分密切相关。本方法为静息态功能磁共振成像的分析开辟了一种新方法，并可能应用于理解衰老或神经退行性疾病期间的大脑动态。
-
- ## INTRODUCTION
	- 分析静息态功能磁共振成像 （fMRI） 的一种途径是使用大规模脑网络动力学的计算模型。这种方法的总体目标是**将观察到的大脑活动与计算模型的动力学库相关联**，可能通过识别最佳模型参数，从而更好地对观察结果进行机械解释。这些计算模型中有一类是基于网络的模型，其中节点代表大脑区域，边代表它们之间的结构连接。这些模型可以受到单个脑成像数据的限制;通常，扩散加权成像数据用于估计边缘权重。大脑区域的局部动力学由所谓的神经群体模型表示：神经元群体活动的低维模型。
	- 在将模型与观测结果联系起来时，直到最近，由于与探索高维参数空间相关的计算成本，研究只关注少量参数。通常，这些参数会全局影响网络动态，例如缩放网络中所有连接强度的参数。然而，近年来，一些工作使用全脑建模框架来探索模型参数的空间异质性的作用。具体来说，研究发现，当区域变异性受到 MRI 衍生的皮质内髓鞘含量估计、功能梯度或基因表达谱的限制时，全脑模型可以更好地再现静息态 fMRI 的特征，并且即使没有先验的限制，也发现了类似的区域变异性。
	- 这些研究中使用的神经群体模型 [例如基于电导的脉冲神经网络的动态平均场模型或神经兴奋性的 Hopf 分叉模型] 通常是通过一系列主要简化得出的，以得出简单的低维神经动力学模型。因此，可以质疑这些模型中包含的动力学结构在多大程度上足以捕捉观察到的数据中表现出的神经动力学的基本要素。**两个不同的神经质量模型会导致相同的结论，还是结果在很大程度上取决于确切的模型形式？**这些问题尚未得到充分回答。
	- **动态系统识别（dynamical system identification）**的最新进展为这个方向开辟了新的可能性，并提出了一个问题，即数据驱动的方法是否可以应用于全脑建模的背景下：我们能否学习一个代表大规模大脑网络每个节点的神经群体的动态系统？这种方法将使我们能够**回避对特定神经群体模型的依赖问题**，这是大规模建模的核心，而是**直接从功能数据中提取该模型**。
	- 我们这项工作的目标是使用基于网络的模型框架来学习全脑动力学模型（图 1）。也就是说，我们假设被连接的神经群体的模型形式，其连接强度来自弥散加权成像。然而，我们没有指定神经群体的功能形式，而是希望**从静息态 fMRI 中观察到的动力学中以数据驱动的方式学习神经群体模型**。使用这个模型，我们想**了解它在不同脑区和受试者之间变化的参数**，这与单个连接组网络一起，导致了跨脑区和受试者的观察到的动态差异。
	- **Fig. 1 Conceptual overview of the method.**
		- ![](https://www.science.org/cms/10.1126/sciadv.abq7547/asset/5ba3b762-8ef5-4606-a08e-ed2459b75640/assets/images/large/sciadv.abq7547-f1.jpg)
		- 该方法允许我们对大脑动力学的网络模型进行参数推断，其中每个节点（或大脑区域）的动力学模型最初是未知的。作为输入（左），它期望多个受试者队列的结构连接矩阵 $$w$$ 以及大脑活动 $$y$$ 的相应观察结果（例如脑区分割的静息态 fMRI）。受区域动力学通用模型结构（中）的约束，**它学习节点动力学f的动力学模型和状态到观测的投影模型g**。动力学模型 f 为所有受试者和区域共享，但它**取决于受试者特定参数** $$\theta_s$$ **和区域特定参数** $$\theta_r$$ 。这些也是从数据以及系统 $$x$$ 的隐藏状态和特定主题的外部输入 $$u_{ext}$$ 中推断出来的，由给定主题的所有区域共享。**所有系统状态、特定于主题和区域的参数以及外部输入都被概率地推断为正态分布，也就是说，我们推断每个参数的均值和方差。**
	- 鉴于这种方法避免了对区域动态特定形式的假设，所需的框架将有可能**独立验证传统方法中使用的方法与预定义的神经群体模型**（例如对区域动态性质的假设）并支持他们的发现（例如关于区域异质性在全脑动力学中的作用）。最终，这种方法可能会导致新一代更具表现力、数据驱动的大规模大脑动力学网络模型。
	- 这项工作的核心是**数据驱动的非线性动力系统识别问题**。近年来引入了许多方法，并应用于物理和生命科学的各个领域 （ 9 – 14 ），包括所有尺度的神经科学 （ 15 – 17 ）。动力学系统的表示和推理方法使用了多种方法：Brunton 等人。 （ 9 ） 引入了**非线性动力学的稀疏识别 （SINDy） 方法**，该方法使用稀疏回归来查找预定义的非线性函数库的系数，从而生成人类可读形式的常微分方程 （ODE）。一些作者通过**混合局部线性动力学来近似非线性系统**;这些方法包括用消息传递算法训练的**切换线性动态系统** （ 10 ， 13 ） 或变分推理学习固定点位置和相关的雅可比矩阵的方法 （ 11 ）。其他方法包括使用**期望最大化算法** （ 14 ， 16 ） 训练的**分段线性激活的递归神经网络**，依赖于**变分自动编码器**架构，用递归神经网络 （ 15 ） 表示动态系统，以及**非线性系统的分层参数化** （ 12 ）。这些方法在计算成本、结果重建的质量、实现的复杂性和结果系统的可解释性方面有所不同。
	- 我们的问题有几个特殊之处，无法直接采用现有的方法，因此我们开发了本文介绍的方法：
		- 1)我们希望在基于网络的大规模脑动力学模型的框架内操作，这意味着我们希望将已知的结构连通性纳入全脑模型。因此，该方法必须**允许预先指定的网络连接**。
		- 2)我们感兴趣的是噪声驱动的系统，即**系统由随机微分方程而不是确定性的微分方程来描述**。现有的一些方法只关注确定性微分方程，只考虑观测噪声，而不考虑底层系统中的噪声。
		- 3)它是神经群体的理想参量化，具有区域和被试参数。当遇到多个相关系统的系统辨识问题时，许多现有的方法并没有提供一种共享所学习动力学的方法，相反，这些系统是独立推断出来的。在这里，我们**只希望推断出一个动力系统，其被试间和区域间的差异仅通过区域和被试参数表示**。
		- 4)这是一个**部分观测问题**。有时假设所有的状态变量都被观察到，这样就大大简化了推理问题。我们假设我们**只有区域动力学的一维(1D)观察(如区域 fMRI 时间序列)** ，这意味着多个系统状态是隐藏的，也需要推断。
	- 为了解决这个问题，我们使用**摊销变分推理或变分自动编码器**（18）的框架，特别是受到其在推断神经群体动态（[Inferring single-trial neural population dynamics using sequential auto-encoders | Nature Methods](https://www.nature.com/articles/s41592-018-0109-9)）和具有层次结构的动态系统（[Efficient Amortised Bayesian Inference for Hierarchical and Nonlinear Dynamical Systems (mlr.press)](https://proceedings.mlr.press/v97/meeds19a.html)）中的应用的启发。简而言之，我们的系统由一个编码网络（**将观测到的时间序列映射到特定于被试和区域的参数以及源空间中的轨迹**）、表示动力系统的神经网络以及充当从源空间到观察空间解码器的观测模型组成。这些经过联合训练，以最大化**证据下限 (ELBO)**（[The evidence lower bound (ELBO) - Matthew N. Bernstein (mbernste.github.io)](https://mbernste.github.io/posts/elbo/)），以便训练模型的预测与原始数据非常相似。
	- 在这项工作中，我们在**两个合成数据集上测试**我们的方法，这些数据集是用大规模大脑建模中常用的两种模型生成的：基于电导的尖峰神经网络的平均场模型，或简称为平均场模型（7），以及Hopf 分岔模型 (8)。对于这两个测试用例，我们使用了由八名受试者组成的队列，这些受试者具有真实的结构连接组，并且模型参数在受试者和大脑区域之间有所不同。我们表明，经过训练的生成模型可以重现原始数据集的许多特征，并**证明该方法可以提取与用于模拟的原始参数密切相关的区域和特定于被试的参数**。
	- 最后，我们将该方法**应用于人类连接组计划 (HCP) 的 100 名受试者的静息态 fMRI 数据** (19)。我们发现，推断的动态可以描述为在节点和网络级别上围绕单个固定点的噪声波动。该方法可靠地发现了三个对动力学具有清晰和独特功能的区域参数，其中一个与基因表达空间图的第一主成分密切相关。我们进一步发现，**功能连接（FC）仅部分再现**，并且**严重依赖于所有区域共享的外部输入**，并且**仅在很小程度上依赖于网络交互**。
-
- ## RESULTS
	- 结果部分由三部分组成。在第一部分中，我们介绍了所开发方法的基本思想，它的详细描述可以在方法中找到。第二部分对合成数据，即参数已知的计算模型产生的数据进行了验证。第三部分将该方法应用于人体静息状态 fMRI 数据，并对结果进行分析。
	- ### Amortized variational inference for networks of nonlinear dynamical systems
		- 我们遵循大规模脑网络建模的总体框架，并假设对于特定被试，大脑区域 j 的观测值 $y_j(t))$ 由下述动力系统生成
			- $$\dot{X}_j(t) = f[X_j(t),\theta_j^r,\theta^s,u_{ext}(t),u_j(t)]+\eta_j(t)$$
			- $$y_j(t)=g[X_j(t)]+\nu_j(t)$$
		- 其中$$X_j(t)\in \mathbb{R}^{n_s}$$是t时刻的状态，$$\theta_j^r\in \mathbb{R}^{m_r}$$是区域特异的参数，$$\theta^s\in \mathbb{R}^{m_s}$$是被试特异的参数。
		- $u_{ext}(t)$是外部输入，由同一个被试的所有脑区共享。
		- $$u_j(t)=\sum_{i=1}^n{w_{ij}g_c[X_i(t)]}$$是区域j的网络输入，其中$w_{ij}$即结构连接矩阵。
		- 函数$f,g,g_c$均是未知的，$\eta_j(t)$和$\nu_j(t)$分别是系统噪声和观测噪声。
		- 从多个受试者的观察时间序列中，我们希望推断出对于所有受试者都相同的演化函数 f 和观察函数 g，以及特定于区域和受试者的参数 $$\theta_j^r$$ 和 $$\theta^s$$ 以及与时间相关的外部输入 $$u_{ext}$$。为此，我们采用摊销变分推理（18）的一般框架，其参数具有层次结构（图S1B）（12）。我们考虑状态 $$X_j$$，参数 $$\theta_j^r$$ 和 $$\theta^s$$，外部输入 $$u_{ext}$$ 作为潜在变量并寻求由多元高斯分布表示的近似后验分布。本着摊余变分推理的精神，我们不直接优化它们的参数，而是通过编码器函数 $$h_1$$、$$h_2$$、$$h_3$$ 和 $$h_4$$，将数据转换为潜在变量（分别为系统状态、区域和被试参数以及外部输入）。
		- 出于计算易处理性的原因，我们强假设观测函数和耦合函数是相同的，$g == g_c$。这使我们能够==有效地将网络问题解耦为已知网络输入的非耦合区域==，因此我们可以将一个被试的一个区域的时间序列视为单个数据点。我们根据讨论的结果回到这个选择及其可能的含义。
		- 我们用**通用人工神经网络表示非线性函数 f，将函数 g 表示为线性变换**。推理问题最终转化为成本函数 ELBO 的优化，**ELBO将在** f、g、$$h_1$$、$$h_2$$、$$h_3$$ 和 $$h_4$$ **的权重以及系统和观测噪声的方差上最大化**。优化后，我们获得了用函数 f 和 g 来描述动力系统，区域和被试参数 $$\theta_j^r$$ 和 $$\theta^s$$ 的概率表示以及外部输入 $$u_{ext}$$ 的值，以及状态空间 xj 中观测值的投影。推断的参数 $$\theta_j^r$$ 和 $$\theta^s$$ 不具有机制意义；然而，它们可以提供区域和被试的（不）相似性的度量，并且可以通过推断的动力系统 f 进行解释。
		- ### **关于变分推断**
		  collapsed:: true
			- #### amortized variational inference 是什么
			  collapsed:: true
				- [Amortized Variational Inference (AVI) 是一种用于近似概率模型中难以处理的后验分布的方法](https://arxiv.org/abs/2307.11018)[1](https://arxiv.org/abs/2307.11018)[。AVI 的主要特点是它学习一个全局推断函数，该函数将每个观察值映射到其局部潜变量的近似后验](https://arxiv.org/abs/2307.11018)[1](https://arxiv.org/abs/2307.11018)。
				- [在传统的变分推断中，需要对每个数据点优化 ξ_i，计算成本高，特别是当该优化被嵌入一个全局参数的更新循环时](https://www.dazhuanlan.com/2020/03/01/5e5b28acefd34/)[2](https://www.dazhuanlan.com/2020/03/01/5e5b28acefd34/)[。而 Amortized Inference 的基本想法是使用一个强大的预测器来基于 x_i 的特征预测最优的 z_i，即 z_i=f(x_i)](https://www.dazhuanlan.com/2020/03/01/5e5b28acefd34/)[2](https://www.dazhuanlan.com/2020/03/01/5e5b28acefd34/)[。这样，局部变分参数被一个函数替代，并且这个函数的参数是对所有数据点共享的，也就是说推断是 amortized（平摊、分期——没有标准术语翻译）的，不是一下子出来的](https://www.dazhuanlan.com/2020/03/01/5e5b28acefd34/)[2](https://www.dazhuanlan.com/2020/03/01/5e5b28acefd34/)。
				- [总的来说，Amortized Variational Inference 是一种有效和可扩展的方法，因为它利用参数化函数来学习近似后验密度参数](https://arxiv.org/abs/2209.10888)[3](https://arxiv.org/abs/2209.10888)[。这使得 AVI 比许多基于采样的技术更快](https://arxiv.org/abs/2209.10888)[3](https://arxiv.org/abs/2209.10888)[。然而，传统的 VI 算法无法扩展到大型数据集，并且无法在不重新运行优化过程的情况下立即推断超出范围的数据点](https://arxiv.org/abs/2209.10888)[3](https://arxiv.org/abs/2209.10888)[。最近在该领域的发展，如随机、黑箱和 amortized-VI，已经帮助解决了这些问题](https://arxiv.org/abs/2209.10888)[3](https://arxiv.org/abs/2209.10888)。
			- #### 你能给我一个例子吗?
				- [当然可以。在深度生成模型中，Amortized Variational Inference (A-VI)被用作一种计算技巧，以加速对局部潜变量的推断](https://arxiv.org/abs/2307.11018)[1](https://arxiv.org/abs/2307.11018)[。例如，考虑一个深度生成模型，如变分自编码器（VAE）。在这种模型中，我们有一个编码器网络，它将观察数据映射到潜在变量的分布，以及一个解码器网络，它将这些潜在变量映射回数据空间](https://arxiv.org/abs/2307.11018)[1](https://arxiv.org/abs/2307.11018)。
				- [在训练过程中，我们希望学习编码器和解码器的参数，以便最大化观察数据的对数似然](https://arxiv.org/abs/2307.11018)[1](https://arxiv.org/abs/2307.11018)[。然而，由于后验分布是不可解的，我们需要使用变分推断来近似它](https://arxiv.org/abs/2307.11018)[1](https://arxiv.org/abs/2307.11018)[。在传统的变分推断中，我们会为每个数据点学习一个独立的近似后验分布](https://arxiv.org/abs/2307.11018)[1](https://arxiv.org/abs/2307.11018)[。这需要大量的计算，并且难以扩展到大型数据集](https://arxiv.org/abs/2307.11018)[1](https://arxiv.org/abs/2307.11018)。
				- [相反，在 Amortized Variational Inference 中，我们学习一个全局的推断函数（即编码器），它将每个观察值映射到其局部潜变量的近似后验](https://arxiv.org/abs/2307.11018)[1](https://arxiv.org/abs/2307.11018)[。这样，我们就可以一次性地为所有数据点学习近似后验分布](https://arxiv.org/abs/2307.11018)[1](https://arxiv.org/abs/2307.11018)[。这大大减少了计算需求，并使得方法可以扩展到大型数据集](https://arxiv.org/abs/2307.11018)[1](https://arxiv.org/abs/2307.11018)。
				- [总的来说，Amortized Variational Inference 提供了一种有效且可扩展的方法来进行变分推断，并且已经被广泛应用于深度生成模型的训练和推断](https://arxiv.org/abs/2209.10888)[2](https://arxiv.org/abs/2209.10888)[1](https://arxiv.org/abs/2307.11018)。
			- #### 什么是变分推断
				- [变分推断（Variational Inference，简称VI）是贝叶斯近似推断方法中的一大类方法，它将后验推断问题巧妙地转化为优化问题进行求解](https://zhuanlan.zhihu.com/p/88336614)[1](https://zhuanlan.zhihu.com/p/88336614)[2](https://blog.csdn.net/c9Yv2cf9I06K2A9E/article/details/102735795)[。相比另一大类方法马尔可夫链蒙特卡洛方法（Markov Chain Monte Carlo, MCMC），VI 具有更好的收敛性和可扩展性（scalability），更适合求解大规模近似推断问题](https://zhuanlan.zhihu.com/p/88336614)[1](https://zhuanlan.zhihu.com/p/88336614)[2](https://blog.csdn.net/c9Yv2cf9I06K2A9E/article/details/102735795)。
				  [在变分推断中，我们不是直接求后验概率p(z|x)，而是求与其KL divergence最小的优化问题q*(z) = argmin(q(z)∈Q) KL(q(z)||p(z|x))](https://zhuanlan.zhihu.com/p/49401976)[3](https://zhuanlan.zhihu.com/p/49401976)[。其中，KL(q(z)||p(z|x)) = E[logq(z)] - E[logp(z|x)]，期望均是对于分布q(z)上的期望](https://zhuanlan.zhihu.com/p/49401976)[3](https://zhuanlan.zhihu.com/p/49401976)[。我们可以将其进一步展开为KL(q(z)||p(z|x)) = E[logq(z)] - E[logp(z,x)] + logp(x)](https://zhuanlan.zhihu.com/p/49401976)[3](https://zhuanlan.zhihu.com/p/49401976)[。注意这里最后一项为logp(x)，我们又回到最初的边缘分布的问题难以求解](https://zhuanlan.zhihu.com/p/49401976)[3](https://zhuanlan.zhihu.com/p/49401976)。
				- [由于我们无法直接计算KL，所以我们改变优化目标为与KL前两项相关的量evidence lower bound（简称ELBO）：ELBO(q)= E[logp(z,x)] -E[logq(z)]](https://zhuanlan.zhihu.com/p/49401976)[3](https://zhuanlan.zhihu.com/p/49401976)[。可以看到，ELBO是负的KL再加上logp(x)，由于logp(x)相对于q(z)的梯度为零，所以极小化KL divergence的问题与极大化ELBO的优化问题是等价的](https://zhuanlan.zhihu.com/p/49401976)[3](https://zhuanlan.zhihu.com/p/49401976)[。因此，变分推断将推断问题转化为了求极值的优化问题](https://zhuanlan.zhihu.com/p/49401976)[3](https://zhuanlan.zhihu.com/p/49401976)。
				- [总的来说，变分推断是一种强大且灵活的工具，它可以用于处理许多复杂的统计模型，并且已经在机器学习和统计领域中得到了广泛的应用](https://zhuanlan.zhihu.com/p/88336614)[1](https://zhuanlan.zhihu.com/p/88336614)[2](https://blog.csdn.net/c9Yv2cf9I06K2A9E/article/details/102735795)。
			- #### 什么是马尔科夫链蒙特卡洛方法
				- [马尔科夫链蒙特卡洛方法（Markov Chain Monte Carlo，简称MCMC）是一种使用马尔科夫链进行随机抽样以进行近似数值计算的方法](https://zh.wikipedia.org/wiki/%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E9%93%BE%E8%92%99%E7%89%B9%E5%8D%A1%E6%B4%9B)[1](https://zh.wikipedia.org/wiki/%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E9%93%BE%E8%92%99%E7%89%B9%E5%8D%A1%E6%B4%9B)[。MCMC的基本思想是构建一条马尔科夫链，使其平稳分布就是要进行抽样的分布](https://zh.wikipedia.org/wiki/%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E9%93%BE%E8%92%99%E7%89%B9%E5%8D%A1%E6%B4%9B)[1](https://zh.wikipedia.org/wiki/%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E9%93%BE%E8%92%99%E7%89%B9%E5%8D%A1%E6%B4%9B)[。首先基于该马尔科夫链进行随机游走，产生样本的序列，然后使用该平稳分布的样本进行近似的数值计算](https://zh.wikipedia.org/wiki/%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E9%93%BE%E8%92%99%E7%89%B9%E5%8D%A1%E6%B4%9B)[1](https://zh.wikipedia.org/wiki/%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E9%93%BE%E8%92%99%E7%89%B9%E5%8D%A1%E6%B4%9B)。
				- [MCMC方法可以应用于概率分布的估计、定积分的近似计算、最优化问题的近似求解等问题，特别是被应用于统计学习中概率模型的学习与推理，是重要的统计学习计算方法](https://zhuanlan.zhihu.com/p/250146007)[2](https://zhuanlan.zhihu.com/p/250146007)。
				- [例如，假设你有一个复杂的多维概率分布，你想从这个分布中抽取样本。直接抽取可能非常困难，但是你可以构建一个马尔科夫链，其平稳分布就是你感兴趣的分布。然后，你可以让这个马尔科夫链运行一段时间，生成一系列样本。这些样本将会越来越接近你感兴趣的分布。最后，你可以使用这些样本来估计分布的各种性质，比如它的均值、方差等](https://zhuanlan.zhihu.com/p/37121528)[3](https://zhuanlan.zhihu.com/p/37121528)[2](https://zhuanlan.zhihu.com/p/250146007)[1](https://zh.wikipedia.org/wiki/%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E9%93%BE%E8%92%99%E7%89%B9%E5%8D%A1%E6%B4%9B)。
				- [总的来说，MCMC提供了一种强大而灵活的工具，可以用来处理许多复杂的统计问题](https://zhuanlan.zhihu.com/p/37121528)[3](https://zhuanlan.zhihu.com/p/37121528)[2](https://zhuanlan.zhihu.com/p/250146007)[1](https://zh.wikipedia.org/wiki/%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E9%93%BE%E8%92%99%E7%89%B9%E5%8D%A1%E6%B4%9B)。
			- #### 什么是马尔科夫链
				- [马尔科夫链（Markov Chain）是一种随机过程，它具有“无记忆性”，即下一状态的概率分布只能由当前状态决定，在时间序列中它前面的事件均与之无关](https://zhuanlan.zhihu.com/p/448575579)[1](https://zhuanlan.zhihu.com/p/448575579)[2](https://zh.wikipedia.org/wiki/%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E9%93%BE)[。这种特定类型的“无记忆性”称作马尔科夫性质](https://zhuanlan.zhihu.com/p/448575579)[1](https://zhuanlan.zhihu.com/p/448575579)[2](https://zh.wikipedia.org/wiki/%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E9%93%BE)。
				- [马尔科夫链可以是离散状态空间（一组随机变量的可能值的集合）或者有离散索引集合（通常表示时间），因此，马尔科夫链有许多变种](https://zhuanlan.zhihu.com/p/448575579)[3](https://blog.csdn.net/qq_43428310/article/details/106684182)[。通常所说的「马尔科夫链」是指具有离散时间集合的过程，也就是离散时间马尔可夫链（DTMC）](https://zhuanlan.zhihu.com/p/448575579)[3](https://blog.csdn.net/qq_43428310/article/details/106684182)。
				- [马尔科夫链作为实际过程的统计模型具有许多应用。在马尔科夫链的每一步，系统根据概率分布，可以从一个状态变到另一个状态，也可以保持当前状态](https://zhuanlan.zhihu.com/p/448575579)[2](https://zh.wikipedia.org/wiki/%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E9%93%BE)[。状态的改变叫做转移，与不同的状态改变相关的概率叫做转移概率](https://zhuanlan.zhihu.com/p/448575579)[2](https://zh.wikipedia.org/wiki/%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E9%93%BE)[。例如，随机漫步就是马尔科夫链的一个例子。在随机漫步中每一步的状态是在图形中的点，每一步可以移动到任何一个相邻的点，在这里移动到每一个点的概率都是相同的（无论之前漫步路径是如何的）](https://zhuanlan.zhihu.com/p/448575579)[2](https://zh.wikipedia.org/wiki/%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E9%93%BE)。
				- [总的来说，马尔科夫链是机器学习和人工智能的基石，在强化学习、自然语言处理、金融领域、天气预测、语音识别方面都有着极其广泛的应用](https://zhuanlan.zhihu.com/p/448575579)[1](https://zhuanlan.zhihu.com/p/448575579)。
			- 什么是 amortized variational inference
				- [Amortized Variational Inference : An Overview | by Sertis | Medium](https://sertiscorp.medium.com/amortized-variational-inference-an-overview-f246c1e11e11)
				- [[2307.11018] Amortized Variational Inference: When and Why? (arxiv.org)](https://arxiv.org/abs/2307.11018)
				- [[2209.10888] Amortized Variational Inference: A Systematic Review (arxiv.org)](https://arxiv.org/abs/2209.10888)
				- [Collapsed Amortized Variational Inference for Switching Nonlinear Dynamical Systems (mlr.press)](https://proceedings.mlr.press/v119/dong20e.html)
				- 变分推断基础：
					- 变分推断是一种用于近似复杂概率模型中后验分布的方法。它的目标是找到一个易于处理的分布来近似真实的后验分布。传统的变分推断方法为每个数据点单独优化变分参数。
				- 摊销变分推断的定义：
					- 摊销变分推断是变分推断的一种改进形式。它使用一个参数化的模型（通常是神经网络）来直接从数据预测变分参数，而不是为每个数据点单独优化这些参数。这种方法"摊销"了推断的计算成本，使得在新数据上的推断变得更快。
				- 神经网络的应用：
					- 在摊销变分推断中，深度学习模型被广泛用作随机函数，用于创建变分分布的参数。这种方法利用了神经网络强大的表达能力和泛化能力。
				- 优势：
					- 效率：一旦训练完成，对新数据点的推断变得非常快速。
					- 泛化：学习到的推断模型可以泛化到未见过的数据。
					- 可扩展性：适用于大规模数据集和在线学习场景。
				- 应用领域：
					- 摊销变分推断在多个机器学习领域都有应用，包括但不限于：
						- 变分自编码器（VAEs）
						- 主题模型
						- 时间序列分析
						- 强化学习
				- 挑战和研究方向：
					- 尽管摊销变分推断带来了许多优势，但它也面临一些挑战：
						- 模型选择：如何选择合适的神经网络架构来参数化推断模型。
						- 优化难度：训练过程可能比传统变分推断更加复杂。
						- 理论保证：需要更多的理论工作来理解其性能界限和收敛性质。
				- 具体应用示例：
					- 在非线性动态系统中，研究者提出了一种基于摊销变分推断的方法来处理切换非线性动态系统。这种方法能够有效地推断系统状态和模式切换，展示了摊销变分推断在复杂时间序列模型中的应用潜力。
				- 总结：
					- 摊销变分推断是一种创新的方法，它结合了深度学习的强大功能和变分推断的统计基础。通过学习一个通用的推断模型，它大大提高了推断的效率和可扩展性。这种方法在处理大规模数据集和复杂概率模型时特别有效，为机器学习中的概率推断开辟了新的可能性。随着研究的深入，我们可以期待看到这种方法在更多领域的应用和理论上的进一步发展。
	- ### Validation on synthetic data
		- #### *Evaluation workflow*
			- 我们在两个合成数据集上测试了所提出的方法，其中数据由全脑建模中常用的模型生成。首先是 **Hopf 分叉模型** （ 8 ），如图 2 所示。这是一个双方程神经群体模型，其中，根据分岔参数 ai 的值，动力学**要么是围绕稳定固定点驱动的噪声（对于ai< 0），要么是频率为 fi 的振荡（对于ai> 0）**。在合成数据集中，这两个参数在不同脑区随机变化。第二个模型是**参数平均场模型 （pMFM）** （ 7 ），如图 3 所示。这是一个单方程模型，根据网络输入，它可以被推入**高单稳态、低单稳态或双稳态**。状态之间的切换是由噪声驱动的，我们改变了不同大脑区域的噪声强度。
			- **Fig. 2****. Hopf model test case: example subject.**
				- ![](https://www.science.org/cms/10.1126/sciadv.abq7547/asset/f94fa33f-3120-40f1-908e-c0e44ed1b3f5/assets/images/large/sciadv.abq7547-f2.jpg)
				- (A) 训练数据是使用大脑动力学的网络模型进行模拟的，其中在每个节点上放置了一个Hopf神经质量模型。
				- (B) 这些节点通过源自扩散加权成像的连接组进行耦合，并由特定于受试者的耦合参数G进行缩放。
				- (C) 分岔参数ai和固有频率fi的值在不同脑区之间有所变化。
				- (D) 原始模型生成的时间序列，包括三个示例（底部）和计算得出的功能连接（FC）（右侧）。
				- (E) 所有区域的推断区域参数（左上；突出显示的示例节点）和推断的特定于受试者的参数（左下；灰色显示，与数据集中所有受试者的参数一起）。十字/线条的跨度对应于推断高斯分布的两个标准差。底部：由于标准差较小，添加了圆圈以便于视觉辅助。右侧是三个示例节点在状态空间中的推断动态。矢量场是在假设零网络输入和推断参数的情况下评估的。背景颜色表示速度幅度；黄线表示节点活动的示例模拟时间序列；黑面和白面圆圈分别表示稳定和不稳定的固定点。在最上面的面板中，一个不稳定固定点和一个稳定固定点在视觉上重叠。
				- (F) 推断的区域参数，颜色由分岔参数ai（上）和频率fi（下）的真实值决定。分岔参数与推断的θ相关，而频率仅在振荡区域（即ai > 0的区域）与θ相关。
				- (G) 使用训练后的模型和推断参数生成的时间序列的一个示例。数据的重要特征在区域水平（幅度和频率）和网络水平（功能连接）上都得到了保留。
			- **Fig. 3****. pMFM test case: example subject.**
				- ![](https://www.science.org/cms/10.1126/sciadv.abq7547/asset/ebb85a5e-3100-4555-a306-0612b24f36a4/assets/images/large/sciadv.abq7547-f3.jpg)
				- （A至C) 训练数据是使用pMFM神经质量网络进行模拟的。根据网络输入，这些神经群体可能被迫进入单稳态（下态或上态）或双稳态。动力学由噪声驱动，噪声强度在不同区域间有所变化。
				- (D) 使用原始模型生成的时间序列和功能连接（FC）。底部面板显示了三个示例，右侧是100秒的时间窗口。
				- (E) 推断的区域参数（左上）和特定于受试者的参数。由于标准差较小，添加了圆圈以便于视觉辅助。右侧是三个示例节点在状态空间中的推断动态。矢量场是在假设网络输入u = 1的情况下，使用推断的参数进行评估的。背景颜色表示速度幅度；黄线表示节点活动的示例模拟时间序列；黑面和白面圆圈分别表示稳定和不稳定的固定点。
				- (F) 推断的区域参数，颜色由噪声强度参数的真实值决定（上）。原始参数存储在推断参数空间的对角线上。下：根据原始时间序列的平均值进行着色，这不代表原始模型参数，而是一个数据特征。
				- (G) 使用训练后的模型和推断参数生成的时间序列的一个示例。区域特定的特征（在状态之间切换和噪声程度）得到了很好的保留。区域相关性的结构也得到了再现，但相关性比原始数据弱。请注意，即使区域时间序列表现出双稳态的迹象（上态和下态），**这种双稳态可能是在网络层面上产生的，而不一定是在区域层面上**，这一点从(E)中的相位图可以看出。
			- 这两个模型都用于生成 8 个被试的合成数据，每个被试都有单独的结构连接组，其中包含 68 个 Desikan-Killiany 分块的皮层区域 （20）。连接组由全局耦合强度 G 缩放，我们将其设置为 Hopf 模型的被试之间线性增加，pMFM模型中则是为每个被试设置到最优值。
			- 为了确定所描述方法的性能，我们进行如下操作。首先，我们使用原始模型和区域参数的随机值（图 2D 和 3D）模拟数据。接下来，使用八个受试者的整个数据集，我们训练模型，同时获得由动力学系统的函数 f 描述的训练后的生成模型，以及被试和区域特定参数的概率表示（图 2E 和 3E）。从参数的后验分布中随机采样，并使用随机系统和观察噪声，我们使用训练后的模型重复生成新的时间序列（图 2G 和 3G）。
			- 我们基于以下标准评估训练模型的质量：首先，我们确定**推断出的参数是否与模型的原始参数相关**（参见图2F、3F以及4A和E）；其次，我们希望评估**生成的时间序列特征是否与原始时间序列相似**，这包括区域层面（参见图4B和F）和网络层面（参见图4C、D、G和H）。特别指出，我们使用从后验预测分布中采样的时间序列来评估这种相似性。也就是说，这些时间序列**是使用推断出的参数θr和θs生成的**，但使用随机的系统噪声和观测噪声。**这与从方程26中的后验分布q(x | y, u, c)采样是不同的**。这种评估方法允许我们检验模型不仅能够拟合给定的数据，还能够生成与原始数据具有相似特征的新数据，从而验证模型的泛化能力和对底层动态的捕捉程度。
			- **Fig. 4****. Quantitative evaluation of the synthetic test cases.**
				- https://www.science.org/cms/10.1126/sciadv.abq7547/asset/7cb3fb05-1703-4c1c-aa78-494c217918ce/assets/images/large/sciadv.abq7547-f4.jpg
				- 上排：Hopf模型。下排：pMFM模型。
				- (A和E) 原始参数与推断的区域特定参数（Hopf模型的分岔参数a和频率f，pMFM的噪声强度）和受试者特定参数（耦合强度G）的最优投影之间的非线性相关性。
				- (B和F) 原始时间序列的区域特征与训练后模型生成的特征之间的拟合度。对于Hopf模型，我们展示了时间序列频谱的余弦相似度和方差的差异；对于pMFM，我们展示了观察空间分布的Wasserstein距离和切换次数对数的差异。这些评估基于图2和图3中的示例，所有由训练后模型生成的时间序列，以及正文中描述的替代数据。
				- (C和G) 原始时间序列与生成时间序列的功能连接（FC）之间的拟合度。
				- (D和H) FC矩阵非对角元素的平均值。对于两种模型，相关强度都被低估了，尽管结构得到了保留。在所有面板中，条形显示了（5，95）百分位区间，点表示中位数。统计数据是从8个受试者的后验分布的50个样本中计算得出的[在(A)、(B)、(E)和(F)中分组]，以及68个区域（对于区域特定参数和特征）。使用原始模型的替代分布的统计数据也是从50个样本中计算得出的。
			-
		- #### *Inferred parameters correspond to the original model parameters*
			- 图 2F 中的示例显示了原始区域参数如何与 Hopf 模型的推断参数 θr 相关联。分岔参数 a 映射到推断的参数 $$\theta^r_1$$（顶部），而频率 f 映射到 $$\theta^r_2$$（底部）。然而，后者仅适用于处于振荡状态的区域，即 a > 0。这并不是所提出的方法的缺点：在稳定点状态下，活动主要是噪声驱动的，频率参数的值的影响很小，甚至可以忽略不计（参见图 2D 中的示例 C）。换句话说，无法从数据中识别参数。这反映在推断的参数中。对于 a>0 的区域，推断的参数具有低方差，并且它们的平均值映射到原始频率参数。但是，对于 a < 0 的区域，推断的方差较高，接近前验值 1，并且分布重叠，这表明在此方案中存储的信息不多。
			- 此外，对于 pMFM 测试用例，噪声强度参数得到了很好的识别（图 3F）;但是，特定于区域的参数的第二个维度与区域时间序列的平均值相关。据推测，这是为了让参数可以补偿较弱的网络耦合，我们将在后面讨论。对于这两个示例，特定被试的耦合强度被映射到被试参数 θs（图 2E 和 3E，底部）
			- 拟合优度的定量分析如图 4 （A 和 E） 所示。为了评估它，对于每个原始参数，我们首先通过对后验分布均值进行线性回归来确定参数空间中存储参数的方向。然后，我们反复从参数的后验分布中取样，将它们投影到识别出的子空间上，并计算非线性 Spearman 相关系数 ρ。对于大多数参数，这些值都接近于最优值 1，这表明原始参数确实在推断的参数中被准确恢复。由于上面讨论的不可识别性，频率 f 是例外。但是，如果我们将区域仅限于分岔参数为正的区域，那么相关性就会显著增加，正如所讨论示例所预期的那样。参数相关性和报告的统计数据的进一步说明见图。S2 和 S3。
			- 在图 .S4 中，我们进一步评估了 Hopf 模型中拟合优度如何随着耦合的增加而变化。据推测，**随着耦合的增加，区域时间序列受连通区域活动的影响更大，受其内部参数的影响较小，因此从数据中恢复原始参数更加困难。**这就是我们在振荡状态下观察到的节点的分岔参数 a 和频率 f 的趋势。
		- #### *Trained model reproduces the features of regional time series*
			- 训练模型的关键测试是评估生成的数据是否与用于初始训练的数据相似。**这种相似性不应被理解为复制时间序列，因为它们依赖于特定的噪声实例化，而是应该保留我们认为有意义的特征**。对于这两个测试用例，我们评估了两个特征的相似性。对于具有振荡动力学的 Hopf 模型，我们评估了原始时间序列和生成**时间序列的光谱的余弦相似性以及时间序列方差之间的差异**，因为振荡和定点状态下的节点方差之间的差异很大（图 4B 和图 S5）。对于 pMFM，我们使用两个**分布的 Wasserstein 距离**（也称为Earth mover's distance, EMD），根据 1D 观测空间中的分布（即取随时间折叠的样本）来比较时间序列。pMFM 时间序列的第二个特征是 **up-down 状态之间开关的对数缩放次数**，捕捉了开关动态的时间方面（图 4F 和图 S6）。
			- 我们评估 50 个不同噪声实例的测量，导致每个区域有 50 个不同的时间序列，获得拟合优度指标的分布。还针对三个替代数据评估相同的指标：第一个是原始计算模型，使用不同的噪声实例运行。考虑到这些特征必然取决于初始模拟中使用的特定噪声实例，这提供了对拟合优度方面可以实现的乐观估计。第二个代理是通过在区域和受试者之间随机重新排列原始数据而获得的。第三个替代项只是白噪声，均值为零，方差等于一（由于数据归一化，它等于所有受试者和区域的原始数据集的均值和方差）。
			- 在大多数指标中，**训练后的模型的表现与原始模型相当或稍差**，但明显优于重新洗牌的替代模型和噪声替代模型（图 4、B 和 F；统计测试的数值和结果见表 S2）。例外是光谱与 Hopf 模型的余弦相似度。在这个衡量标准中，重新洗牌代理达到了与训练模型相似的值；这是因为耦合网络中的许多区域以相似的频率振荡。因此，两个随机选择区域的时间序列通常在其光谱的余弦相似性方面达到高分。
		- #### *Functional network structure is reproduced but with lowered strength*
			- 正如训练有素的模型应该能够在单个区域级别上重现原始数据的特征一样，它也应该能够在网络级别上重现相关特征。具体来说，我们评估 FC 的再现效果。一般来说，FC 量化了大脑区域时间序列之间的统计依赖性。虽然有多种方法来衡量它，但最普遍的是时间序列的线性（皮尔逊）相关性，我们在这里也使用它。这个静态 FC 捕捉统计相似性的空间结构；然而，它也有其局限性。值得注意的是，它忽略了 FC 结构（21、22）的时间变化。
			- 两个研究模型的示例表明，**FC 结构得到了很好的再现，但连接强度偏低**，特别是在 pMFM 示例的情况下（图 2G 和 3G）。这在图 4 中对所有受试者进行了进一步分析，并在图 S7和 S8 中进行了可视化。对于 Hopf 模型，对于低耦合值，FC 结构不会被再现（通过原始 FC 和训练模型 FC 的非对角元素之间的 Pearson 相关性来测量；图 4C）。然而，对于原始模型来说也是如此，因为 FC 元素接近于零并且依赖于噪声。对于高耦合值，结构得到了更好的保留，尽管训练后的模型 FC 矩阵之间的相关性稳定在 0.7 左右，即使原始模型之间的相关性进一步增加。此外，非对角 FC 元素平均值的比较表明，训练模型的相关性强度明显偏低（图 4D）。对于 pMFM，耦合系数被设置为针对每个受试者的最佳值（在最大 FC 的意义上）。此外，我们可以看到相关性的良好再现结构（图 4G），尽管强度也有所降低（图 4H）。
			- 这些结果表明，虽然**经过训练的模型可以发现网络耦合的存在，但它系统性地低估了其强度**。鉴于在 pMFM 中，网络输入的强度可以将单个神经群体从单稳态低状态转变为双稳态状态，再转变为单稳态高状态，因此低估的耦合导致需要使用区域参数来补偿缺失的耦合（图 3F）。据推测，网络耦合强度的降低在某种程度上导致了区域参数的不太完美的恢复，因为局部动力学的特征受到网络相互作用的影响。**例如，在 Hopf 模型网络中，强耦合区域一起同步；如果不考虑网络耦合，本地频率参数可能会被大大高估或低估。**
		- #### *Large perturbations of the connectome lead to reduced performance*
			- 为了评估不精确的结构连接组对拟合优度的影响，我们在 pMFM 数据集上使用扰动的连接组训练了模型。也就是说，我们不是原始的连接矩阵 W ，而是**用 Wϵ = W + ε A 来训练模型**，其中 A 是从标准正态分布中提取元素的矩阵，ε > 0 是扰动幅度。此外，我们还使用了对数缩放的连接矩阵。
			- 图 S9 显示了图 4 中的拟合优度指标在使用这些替代连接组后的变化情况。**高扰动幅度降低了区域和被试参数的恢复**（图 S9，A 和 B），也降低了生成的 FC 的相似性（图 S9E）。另一方面，区域特征即使在大扰动下也能得到类似的再现（图 S9，C 和 D）。使用对数标度的连接组也有类似的负面影响，不过没有那么明显。
	- ### Application on human resting-state fMRI
		- 我们将开发的方法应用于从 HCP 获得的人类静息态 fMRI 数据 （ 19 ）。对于 100 名受试者，我们分析了来自一个会话（864 秒，采样率为 0.72）的 fMRI 时间序列，使用 HCP 管道处理，通过 Diffuse Cluster Estimation and Regression (DiCER) 方法 （23） 进一步去噪，并打包成 Desikan-Killiany 分割的 68 个皮层区域 （20）。在未另行提及的情况下，所呈现的结果是通过具有**状态空间维度 ns = 3 和区域参数维度 mr = 3** 的模型以及具有外部输入和结构连接组的标准预处理的变体获得的（有关详细信息，请参见方法）。==我们将被试参数维度 ms 设置为零，因为观察到被试参数收敛存在困难==;这些如图 S10 所示。
		- 我们以图 5 中单个被试的原始数据和推理结果的示例开始本节。对于这个被试，原始时间序列表现出中等强耦合，在处理后的 fMRI 数据中可以看到广泛的模式（图 5A）。我们使用来自所有 100 名受试者的数据训练模型，但**随机选择了 20% 的区域时间序列来评估可能的过拟合**（图 S11）。在第一次检查时，**训练后的模型依赖于节点级别的单稳定点动力学**，并且可以很好地再现原始数据的几个方面（图 5C）：**区域时间序列的噪声特性和低频振荡的存在或缺失在定性层面上与原始数据相似**。此外，存在广泛的波动并反映在 FC 中。我们将在下一段中评估这些和进一步的方面。
		- **Fig. 5****. Example of model inference on a single subject from the HCP dataset.**
			- https://www.science.org/cms/10.1126/sciadv.abq7547/asset/03a7acc6-5ace-4d57-aa9e-65257bd8c3f2/assets/images/large/sciadv.abq7547-f5.jpg
			- (A) 静息态fMRI数据（左上），相应的功能连接（FC）（右上），以及两个示例区域的时间序列（底部）。(B) 推断出的动力系统的相平面。每个面板显示3D系统的2D投影，第三个变量设置为固定点（黑点）的位置。假设网络输入为零并使用推断出的区域特定参数来评估矢量场。背景颜色表示速度大小；黄线是节点活动嵌入网络时的示例模拟时间序列。(C) 由推断模型生成的数据。区域参数设置为推断出的参数，而系统和观测噪声是随机的。**外部输入使用推断出的参数随机生成**。布局与(A)相同。
		- #### *Noisy dynamics around a single fixed point*
			- 图 5 中的示例显示了两个示例区域**围绕单个固定点的噪声动态**。详细研究表明，这**是所有节点的普遍特征**。我们首先考虑已发现的神经群体，将所有参数 θr 以及网络输入 u 和外部输入 u_ext 设为零（图 6A）。从随机初始点模拟动力学，我们发现在没有噪声的情况下，轨迹会迅速收敛到一个固定点。在该固定点处，系统的三个特征值均为实值和负值；因此，该固定点是一个稳定节点。
			- 固定点的数量是否会因参数配置或输入的不同而变化？为了回答这个问题，我们分析了发现的系统，了解区域参数 θr 的 680 个推断配置（100 个受试者中 10 个受试者的 68 个节点;由于计算成本，仅使用了受试者子集）和 u 和 u_ext 的 9 个组合（均设置为 -1、0 和 1）。对于这些配置中的每一种，我们通过将**非线性求根方法**应用于从每个维度的区间 [-2， 2] 中随机选择的 60 个随机初始点，以数值方式定位了不动点（参见方法）。此外，从这些初始点中的每一个，我们在没有噪声的情况下模拟系统，以评估它是否表现出不稳定的动态，无论是周期性的还是混沌的。**没有观察到多稳态**，当在没有系统噪声的情况下进行仿真时，系统总是收敛到固定点，没有非定常（周期性或混沌）行为（图 6B）。
			- **Fig. 6****. Discovered node and network dynamics.**
				- ![](https://www.science.org/cms/10.1126/sciadv.abq7547/asset/15957b06-036f-4027-ae48-3a08f4d366f9/assets/images/large/sciadv.abq7547-f6.jpg){:height 481, :width 689}
				- (A) 未耦合节点的节点动力学，其中θr = 0，u = 0，且uext = 0。左侧子面板显示了从随机初始化点（三角形）到稳定固定点（黑点）的轨迹。红色轨迹在右下子面板中可视化；右上显示了系统在固定点处的特征值。
				- (B) 推断出的未耦合节点的动力学机制。我们分析了680个推断参数配置和u与uext的9种组合下的发现系统（见正文）。
				- (C) 使用已知的结构连接组和推断的区域参数的单个受试者的网络动力学。左侧子面板显示了在没有系统噪声的情况下，从随机初始化点（三角形）收敛到稳定固定点（黑点）的轨迹，在三个选定维度上（三个节点中的x2）。红色轨迹在右下子面板中可视化；右上显示了系统在固定点处的特征值。
				- (D) 推断出的受试者动力学机制。我们使用推断的区域参数和已知的结构连接组分析了网络动力学。对于每个受试者，我们使用后验分布的不同样本重复了四次分析，其中u_ext = 0。在图表中，我们显示了至少有一个参数样本产生多稳态的受试者数量。
			- 有点出乎意料的是，在评估整个互联网络的动态时，情况大多也是如此。与之前对单个节点的分析类似，我们模拟了从随机初始点开始时，在没有噪声的情况下单个主体的耦合网络的动力学（图 6C）。在此设置中，使用被试结构连接组，所有节点都有其推断的参数值，并且外部输入 u_ext 设置为零。对于示例被试，所有轨迹都收敛到一个固定点。固定点处的所有特征值都有一个负实部，但与隔离节点不同的是，一些特征值是复杂的，表明振荡动力学衰减。
			- 我们分析了所有受试者的耦合网络的动态机制，类似于单个节点（图 6D）。对于数据集中的所有 100 个受试者，我们使用了他们的结构连接组并将参数设置为他们的推断值。选择随机初始条件，我们使用寻根方法在数值上搜索固定点，并再次在没有噪声的情况下模拟动力学以评估非稳态行为。对于数据集中的大多数受试者，状态空间包含单个稳定的不动点。系统仅包含 100 名受试者中的 6 名的多个稳定定点；然而，这种多稳定性对生成的动力学的影响并不是立即明显的（图S12）。与节点动力学类似，在没有系统噪声的情况下，没有一个受试者观察到不稳定行为。
		- #### *Three region-specific parameters identified*
			- 接下来，我们将注意力转向特定于区域的参数 θr 。我们首先问这个问题，使用数据可以识别多少个参数。幸运的是，使用的变分自动编码器框架提供了一种通过所谓的后验折叠 （ 24 ， 25 ） 来回答这个问题的方法。**该术语是指生成模型学会忽略部分或全部潜在变量**，并且近似后验与沿这些被忽略维度的先验分布紧密匹配的现象。在我们的例子中，这意味着区域参数 q （ θr ∣ y ， u ， c ） 的**近似后验将沿部分或全部维度坍缩到先验分布** N （0， 1）。这种行为的一个例子可以在图 S10 中看到。
			- 这种现象有时被认为是不可取的，特别是在沿所有潜在维度完全坍塌的极端情况下，因为它阻止了潜在空间的使用，导致次优重建。然而，仅潜在变量子集的部分崩溃也可以被视为一种可取且必要的行为 （ 25 ），表明数据的真实维度;这就是我们在这项工作中采用的解释。具体来说，**我们预计，随着参数空间 mr 的维数增加，将达到参数空间的必要维数，而参数空间的更多维度将未使用**。这就是我们在训练几个参数空间维数 mr 增加到五个维度的模型时看到的（表 1 ）。用先验分布的近似后验的 Kullback-Leibler 散度来量化坍缩现象，我们看到即使 mr 增加，**使用的参数空间也不超过三个维度**。
			- **Table 1****. Quantification of the posterior collapse phenomenon for the regional variables θ****r**** as the dimensionality of the parameter space is increased.**
				- | $$m_r$$ | 1 | 2 | 3 | 4 | 5 |
				  | ---- | ---- | ---- |
				  | $$\theta^r_1$$ | 3.313 ± 0.268 | 2.946 ± 0.209 | 2.846 ± 0.135 | 2.744 ± 0.230 | 2.716 ± 0.133 |
				  | $$\theta^r_2$$ | – | 2.266 ± 0.935 | 2.025 ± 0.786 | 2.238 ± 0.754 | 2.048 ± 0.714 |
				  | $$\theta^r_3$$ | – | – | 0.917 ± 0.562 | 0.713 ± 0.601 | 0.881 ± 0.515 |
				  | $$\theta^r_4$$ | – | – | – | 0.002 ± 0.002 | 0.004 ± 0.007 |
				  | $$\theta^r_5$$ | – | – | – | – | 0.001 ± 0.000 |
				- 每列对应于具有不同数量区域参数 mr 的不同模型 ;每个单元格显示所有区域和所有主体的近似后验和先验 之间的 Kullback-Leibler 散度的平均值和方差。由于推理过程不保证参数空间维度的任何特定顺序，因此我们按递减的 KL 散度对每一列进行排序。接近零的值表示近似后验与先验分布匹配。当维数增加到 mr = 3 以上时，前三个维度的 KL 散度保持稳定，而附加维度中接近零的值表明附加维度实际上未被使用。
			- 参数在推断模型中的作用是什么？我们通过使用训练好的模型生成新数据来演示它们的功能，改变单个参数，同时保持其他参数不变，并使用相同的噪声实例化（图 7，A 到 C）。这一探索表明，**第一个参数会影响低频（低于 0.1 Hz）振荡的存在**。**第二个参数似乎调节了对外部输入的响应**：模拟的时间序列从负值与外部输入的反相关变为正值的相关。最后，**第三个参数调节了对来自网络其余部分的输入的响应**。
			- **Fig. 7****. Effect of the regional parameters on the generated data.**
				- ![](https://www.science.org/cms/10.1126/sciadv.abq7547/asset/69b3d55b-5dc8-4a8f-a7f0-2424c79bd896/assets/images/large/sciadv.abq7547-f7.jpg){:height 453, :width 689}
				- (A至C) 使用训练好的模型，我们在改变一个区域参数的同时模拟单个区域的时间序列。在每个面板中，我们系统地改变一个区域特定的参数，同时保持其他参数设置为零。系统和观测噪声是从标准正态分布中随机生成的，但对所有模拟保持相同。在(A)中，外部输入和网络输入设置为零。在(B)中，外部输入设置为频率为0.014 Hz的正弦波，网络输入设置为零。在(C)中，外部输入设置为零，网络输入设置为频率为0.014 Hz的正弦波。(D至F) 对(A)至(C)中所示参数效应的统计分析。我们重复（n = 1000）模拟了具有随机选择的θr的单个区域的动力学（见正文）。(D) 低频功率（低于0.1 Hz）与θ的关系。(E) 生成的时间序列与外部输入uext的皮尔逊相关系数与θ的关系。(F) 生成的时间序列与网络输入u的皮尔逊相关系数与通过多变量回归识别的θ和θ的线性组合的关系（图S13）。
			- 这些说法得到了生成时间序列的统计分析的支持（图 7，D 到 F 和图 S13）。我们使用训练好的模型和参数 θ 的随机组合反复模拟区域动态r，并评估假设的关系。对于每个模拟 （ n = 1000），参数 θr 是从先验分布 N （ 0 ， I ） 中随机选择的。系统和观测噪声是为每个模拟随机且唯一地生成的。外部输入 u_ext 也是使用学习的参数随机生成的。每个区域都独立于其他区域进行模拟，并且所有模拟的网络输入都设置为相同：网络时间序列 u 是使用经验 fMRI 数据预先计算的，我们选择使用功率在所有数据中占 80 个百分位的时间序列来模拟节点动力学具有不可忽略和真实的网络输入。这项分析显示了$θ^r_1$与生成时间序列的低频功率之间的明确关系，以及$θ^r_2$与生成时间序列和外部输入u_ext之间的相关性。生成的时间序列与网络输入的相关性依赖于$θ^r_1$和$θ^r_3$，表明**并非每个效应都隔离在参数空间的单一维度中**。
			- 通过直接分析推断的动力学系统 f，可以进一步了解这些内容（图 S14）：对不动点特征值的分析显示了$θ^r_1$与最大特征值的明确关系，因此与衰减时间常数的关系。偏导数 ∂fi / ∂uext 和 ∂fi / ∂u 对参数 θ 的依赖性r解释了系统对外部和网络输入的响应的调制。
			- 分析区域特定参数作用的另一种方法是查看它们与结构和功能数据的各种特征的关系。我们将特征分为两类：第一类，从用于模型训练的单个数据中获得的特征，第二类，从外部来源获得且不特定于相关被试的特征。获取特征并使用所有受试者的推断参数，我们对不同的特征进行了多元线性回归（表 2）。本分析中考虑的特征部分是根据从先前分析中获得的理解和相关研究中感兴趣的特征 （ 4 – 6 ） 来选择的。
			- **Table 2****. Results of the multivariate linear regression between the means of the inferred regional parameters θ****r**** and regional features on the individual or population level.**
				- |   | Feature | *R*2 | Weights |
				  | ---- | ---- | ---- |
				  |   |   |   | $$\theta^r_1$$ | $$\theta^r_2$$ | $$\theta^r_3$$ |
				  | Individual data | SC: Node in-strength | 0.55* | −0.60* | 0.03† | −0.57* |
				  |  | SC: Node centrality | 0.35* | −0.41* | 0.17 | −0.48* |
				  |  | fMRI: First PCA eigenvector | 0.44* | −0.00† | 0.86* | 0.05 |
				  |  | fMRI: Second PCA eigenvector | 0.01 | 0.05 | 0.09 | 0.04† |
				  |  | fMRI: Correlation with mean signal | 0.58* | 0.10 | 1.00* | 0.15 |
				  |  | fMRI: Correlation with network input | 0.52* | −0.43* | 0.62* | 0.51* |
				  |  | fMRI: Number of zero-crossings | 0.96* | 0.99* | 0.02 | −0.01 |
				  |  | fMRI: Power below 0.1 Hz | 0.93* | −0.97* | −0.04 | 0.04 |
				  | External data | Neuronal size (Von Economo) | 0.17 | 0.38 | 0.20 | −0.14 |
				  |  | Neuronal density (Von Economo) | 0.25 | −0.46 | −0.22 | 0.20 |
				  |  | Neuronal density (BigBrain) | 0.19 | −0.42 | −0.24 | 0.02† |
				  |  | RSFC principal gradient | 0.07 | 0.27 | 0.07 | 0.03† |
				  |  | T1w/T2w ratio | 0.19 | −0.40 | −0.09 | 0.22 |
				  |  | Gene expression map (first PC) | 0.47* | −0.69* | −0.15 | 0.11 |
				  |  | EI map | 0.14 | −0.33 | −0.23 | −0.18 |
				- 展示的是决定系数R²和回归权重。为了便于视觉辨识，R² > 0.3且权重绝对值 > 0.2的值用星号(*)标出。P > 2.22 × 10⁻⁵的权重用剑号(†)标记（双侧t检验，阈值为0.001，使用Bonferroni方法对45次比较进行校正）。各个特征是从结构连接性(SC)或经过处理和分区的fMRI计算得出的。外部数据包括平均神经元大小和神经元密度、静息态功能连接(FC)的主要梯度、T1w/T2w比率、基因表达空间图的第一主成分，以及EI图。分析使用了6800个数据点（100个受试者，每个68个区域）。数据的可视化可以在图S15和S16中找到。RSFC指静息态功能连接。
			- 利用个人数据，我们评估了与结构连接组特征和区域 fMRI 时间序列的联系。结果与上述参数的效果非常吻合。第一个参数与区域 fMRI 时间序列的频率特征密切相关，具体来说，低于 0.1 Hz 的功率和过零次数。第二个参数最重要的是与平均 fMRI 信号和从受试者 fMRI 数据的主成分分析 （PCA） 获得的第一个特征向量相关联。这与第一主成分对应于外部输入的解释一致，即调制的响应。第三个参数不仅与结构网络的特征有关，主要是节点强度，还与区域 fMRI 时间序列与同一区域的网络输入的相关性有关;这个网络输入也取决于结构网络（ 方程 7 ）。这也与之前建立的调节作用一致。推断参数和单个数据特征之间的关系如图 S15 所示。
			- 利用外部数据，我们将推断的参数与之前关于全脑网络区域异质性研究中使用的多个特征图进行了比较 （ 5 ， 6 ）：Von Economo 和 Koskinas 的神经元大小和密度 （ 26 ），从 BigBrain 获得的神经元密度 （ 27 ），通过扩散嵌入获得的静息态 FC 的主梯度 （ 28 ），近似于从 HCP 队列数据中获得的髓鞘含量的 T1w/T2w 比率 （ 29 ）， 脑相关基因表达的显性成分 （ 5 ） 和从 Allen 人脑图谱 （ 30 ） 获得的激发-抑制 （EI） 图谱 （ 5 ）。只有我们推断的第一个参数与它们中的任何一个密切相关，最重要的是与基因表达空间图的第一个组成部分密切相关，在较小程度上，与来自两个来源的神经元密度以及 T1w/T2w 比率密切相关。推断参数和单个数据特征之间的关系如图 S16 所示。
		- #### *Role of the network coupling in the trained model*
			- 图 5 说明经过训练的模型可以生成具有与原始数据相似的相关结构的网络动态。对所有受试者进行评估后，经过训练的模型会产生与原始数据的 **FC 与平均皮尔逊相关系数 0.53 相匹配**的动态（图 8A，最左列）。虽然这低于相关研究中获得的结果（我们将在讨论中回到这一事实）（3-6），但它表明模型捕获了相当一部分的功能网络结构。然而，我们注意到**FC动态（FCD），即FC随时间的变化，与数据不匹配**（图S18）。
			-
			- **Fig. 8****. The role of the network connectivity and external input in reproducing the correlation structure.**
				- ![](https://www.science.org/cms/10.1126/sciadv.abq7547/asset/91ddd14b-3b1b-45c0-8695-46b57a5791db/assets/images/large/sciadv.abq7547-f8.jpg){:height 212, :width 689}
				- 对数据集中的所有100名受试者，我们使用学习到的区域参数θr生成新数据，但系统和观测噪声是随机抽取的。我们使用两个模型：一个是带外部输入训练的，另一个是不带外部输入训练的。然后，我们在以下四种情况下生成新数据：同时存在外部输入和网络输入（Ext & net），只有外部输入存在而网络连接设为零（Only ext），只有网络输入而外部输入设为零（Only net），以及两者都不存在（None）。对每个受试者，我们进行20次不同噪声实例的模拟。（A）原始数据和生成数据中FC非对角元素的皮尔逊相关系数，针对不同模型变体。每个箱线图由n = 2000个数据点构建。箱体从数据的第一四分位数延伸到第三四分位数，实线表示中位数，虚线表示平均值。须线从箱体延伸1.5倍四分位距。异常值未显示。除了两个都没有输入的变体之间外，所有平均值之间的差异都具有统计显著性（双侧t检验，P < 1 × 10⁻¹⁰）。（B）原始和模拟FC的非对角元素的平均值。每个点对应一个受试者；FC平均值是在20次模拟中取平均
			- 考虑到这些结果和外部输入的存在，我们可以问大脑区域之间的结构连接在模型中起什么作用，以及外部输入在多大程度上引起了相关结构。我们通过比较模型的几种变体的结构再现效果来研究这一点（图 8）。我们考虑经过训练的模型并生成新数据，假设外部输入和网络输入存在或人为设置为零。我们还首先考虑在没有外部输入的情况下训练的模型。
			- 结果表明，**生成的相关结构主要是由外部输入引起的**，当没有外部输入时，FC 相似度的下降就证明了这一点，无论模型是否在有外部输入的情况下进行训练。这同样适用于模拟 FC 的整体强度。尽管如此，网络连接的作用不容忽视，它提高了性能。如果模型一开始就在没有外部输入的情况下进行训练，则只会实现微小的改进，因此，我们不能依赖它来实现相关性结构。
			- 在迄今为止进行的分析中，我们使用了通过流线计数从弥散成像束造影估计的结构连接组。在专注于大规模大脑动力学的研究中，提出了结构连接组预处理的几种变体;这些修改可以增加模拟和原始 FC 的拟合 （ 31 ）。这些预处理选择对这里的影响有多大？我们比较了四种预处理变体（有或没有对数缩放，有或没有添加同位连接;图 S17），并得出结论，它相对较小。使用具有外部输入的模型时，差异很小（所有变体的平均 FC 相关性在 0.529 和 0.560 之间），这可能是因为外部输入占主导地位。**对于没有外部输入的模型，可以看到更有趣的差异;我们特别注意到加强同位连接的积极影响**（线性标度的平均 FC 相关性为 0.178 至 0.237，对数标度的平均 FC 相关性为 0.177 至 0.211）。
-
- ## DISCUSSION
	- ### Main results
		- 这项工作的主要贡献是一种基于网络动力学系统的数据驱动模型的全脑动力学分析方法。利用网络结构和功能数据，该方法使我们能够推断未知的生成动力学系统和因区域和被试而异的参数。它使我们能够分析大规模的大脑动力学和区域异质性，而无需对潜在的动力学系统进行严格的假设，从而为基于模型的大脑动力学分析提供了一种方法。
		- 我们在两个合成数据集上测试了该方法，一个由具有 Hopf 模型的节点组成的网络模型生成（图 2），另一个由具有 pMFM 的网络模型生成（图 3）。对结果的详细分析表明，所提方法能够在单区域级别和网络级别恢复原始参数并再现原始数据的重要特征（图 4）。然而，在这两个测试用例中，FC 的强度都被低估了。
		- 然后，我们将该方法应用于 HCP 的 100 名受试者的人类静息态 fMRI。此应用程序和详细分析导致了几个有趣的结果。首先，在节点级别和网络级别上发现的动力学可以主要表征为围绕单个固定点的噪声驱动波动（图 6）。其次，该方法能够可靠地恢复三个，并且**只有三个区域参数**，对生成的动力学有明显和明显的影响（图 7），其中一个与基因表达空间图的第一个主成分密切相关（表 2）。第三，学习到的模型能够部分再现原始功能数据的相关结构，尽管程度不如以前的工作。为此，它强烈依赖外部输入，而仅弱依赖于网络连接（图 8）。我们将在以下段落中讨论这些结果。
	- ### Discovered dynamics on the node and network level
		- 应用于静息态fMRI数据时，我们训练的模型能够在很大程度上重现原始数据的相关结构。与许多之前链接结构和功能连接（FC）的计算研究不同（2），我们的数据驱动模型**主要依赖外部输入来解释相关结构，而网络耦合只起次要作用**（图8）。此外，**训练后的模型无法产生真实的时变FC**。发现的**单个节点水平的动力学机制可以被描述为围绕单个稳定固定点的噪声波动**。网络中的节点之间弱耦合，导致对大多数受试者而言，网络水平上也呈现围绕单个固定点的噪声动力学。这种推断的动力学系统主要类似于Hopf分岔网络模型（8），所有节点都处于亚临界状态，网络耦合较弱，但增加了外部输入来补偿弱耦合并强制所需的相关结构。
		- 我们的结果在某种程度上与之前的文献相冲突，**之前的研究表明，使用异质网络模型可以获得明显更好的FC矩阵匹配和更高的FCD相似性**。此外，**先前的模型在不使用外部输入的情况下就实现了更好的拟合**（3-6）。而且，这些网络模型的拟合通常表明，**局部动力学依赖于非线性现象，如稳定的振荡动力学、多稳态性，以及在合理参数范围内的多个不同动力学状态**。虽然已经证明，即使使用相对简单的单固定点动力学模型也能实现良好的静态FC匹配（32），但非线性动力学对于生成与观察数据相匹配的丰富时间行为至关重要（33）。考虑到我们的方法只能发现单个固定点动力学，因此预期模型只能产生不令人满意的时变FC匹配。综合来看，我们认为**这些结果反映了推断算法可能存在的缺陷**，而不是对大脑动力学本质的强有力陈述。我们考虑了几个**可能导致这些结果的因素：优化目标、使用的系统识别方法、fMRI预处理、固定的结构连接性，以及通过观察变量耦合的假设**。
		- #### *Optimization target*
			- 首先，让我们评论一下先前的基于网络的建模研究与我们在此采用的系统识别方法之间的方法学差异。先前的工作表明，使用大尺度脑动力学的网络模型可以实现更好的静态FC和FCD匹配（3-6）。这些工作从一个约束良好的模型（在节点动力学和网络结构方面）开始，调整模型参数以使指定特征（如FC或FCD）尽可能地匹配。这是通过使用指定特征的相似性作为代价函数进行参数优化来实现的。值得注意的是，生成的时间序列除了指定特征外，不需要在任何其他方面与原始数据相似。
			- 相比之下，我们的目标是学习观察到的神经活动的生成模型，即在其架构约束下尽可能在所有方面生成与观察数据相似的数据的模型。由于我们假设研究的系统是由噪声驱动的，这种相似性是有限度的：我们不应期望生成的时间序列比系统的新观测更匹配训练数据。因此，确切的时间序列可能会不同，但理想情况下，在新观测中（至少部分）保留的特征，如FC、FCD的时间独立特征，或单个时间序列的能量和频谱，也应在模拟信号中以与重复观测相同的程度保留。
			- 我们使用变分自编码器框架来实现这一目标。在此框架下，代价函数由重构质量项（公式13）和后验正则化项（公式14和15）组成。重构质量项量化了当系统状态从后验分布中抽取时时间序列的相似性。**如果架构足够有表现力并且可以很好地训练，那么聚合后验分布**[qφ(z∣x)*q**φ*​(*z*∣*x*)（i索引所有区域和受试者）（34）**将覆盖先验分布**，这是由于正则化项的影响。这反过来意味着，使用从先验分布中抽取的噪声进行模拟将产生类似于训练数据的时间序列。
			- 总之，在我们的方法中，观察到的FC和模拟FC的匹配是理想的，可以用作训练模型质量的衡量标准，但由于它不是直接优化的，所以其他直接针对它的方法能够取得更好的结果并不令人惊讶。**我们得到的是一个生成模型，它努力在所有方面模仿原始数据，而不指定应该针对哪些数据特征**。
		- #### *Method of system identification*
			- 毫无疑问，动力系统中函数f的参数化选择以及所使用的学习算法会影响从数据中可以学习和实际学习到的动力学性质。我们的方法导致发现了一个主要依赖单一固定点动力学的系统，其结果之一是训练后的系统无法重现静息态fMRI的复杂时变FC。因此，未来研究的一个理想目标是开发一种更强大的推断方法，能够克服这一缺点。这样的目标**要求函数f的参数化具有足够的表达能力，能够很好地表示广泛的非线性动力学，同时，最优参数配置可以通过所选择的优化算法达到**。具体到我们的问题，当要学习的神经群体模型嵌入到网络中时，这一点必须成立；我们将在后面的段落中回到这个耦合问题。
			- 幸运的是，现有的工作提供了许多系统识别方法的变体，虽然它们没有在网络环境中应用，但在寻找具有改进收敛性能的方法时可以进行探索：例如，Duncker等人（11）依赖于以一组固定点为条件的高斯过程来学习系统动力学，并证明了其在多稳态动力系统上的有效性。Nassar等人（13）使用树结构来划分状态空间，并在每个分区中用线性动力学来近似系统。Koppe等人（16）使用分段线性递归神经网络来分析fMRI数据。Schmidt等人（14）后来扩展了这项工作，引入了一种方法，通过使用动力系统的正则化方案在状态空间中创建慢流形，更好地近似具有多个时间尺度的系统。
			- 值得强调的是，不仅需要考虑函数f的参数化，还需要考虑整个训练框架：在对其动力系统识别架构进行广泛基准测试时，Brenner等人（35）显示，**同一架构通过反向传播和教师强制训练为确定性系统，或通过变分推断方法训练为随机系统，其性能存在显著差异。**
		- #### *fMRI preprocessing*
			- 众所周知，fMRI数据包含各种非神经起源的结构化空间和时间伪影。然而，如何区分和去除广泛分布的非神经起源偏差（被认为与理解大脑动力学无关）同时保留由神经源引起的空间结构信号，这一点仍存在争议（23，36，37）。在大尺度脑建模的背景下，保留广泛分布的信号偏差可能导致拟合不相关的伪影。另一方面，使用全局均值回归等方法去除这些偏差可能会删除相关信息并引入人为的反相关。
			- 最近，Aquino及其同事（38）提供了一个说明预处理危险性的典型例子。在他们的研究中，作者们检查了三种去除fMRI数据中广泛分布偏差的方法：不进行校正、使用DiCER方法（23）进行弥散簇估计和回归，以及使用全局均值回归。他们证明，**模型拟合的结果，即估计的模型参数，强烈依赖于所选择的fMRI预处理方法（[On the intersection between data quality and dynamical modelling of large-scale fMRI signals - ScienceDirect](https://www.sciencedirect.com/science/article/pii/S105381192200180X)）。**
			- 在本研究中，我们使用了DiCER方法（23），该方法旨在去除广泛分布的偏差，比全局均值回归更加精细。尽管如此，仍然存在相当大的广泛分布波动，这解释了为什么外部输入在我们训练的模型中扮演如此重要的角色，以及为什么即使没有网络连接，模型也能较好地匹配FC。对于未来的研究，我们强烈建议仔细考虑和测试fMRI预处理的影响。处理这个问题的一种灵活方式是，不进行预处理，而是直接将可疑的神经和非神经源整合到模型中。这样，相关和不相关的信号源可以在一个框架内进行研究；然而，更复杂的模型会使模型拟合变得更具挑战性。
		- #### *Fixed structural connectivity*
			- 我们的方法假设局部动力学耦合所通过的结构连接组是已知的。然而，我们能获得的只是来自扩散纤维追踪的估计，这受到一系列偏差的影响（39，40）。我们的结果表明，虽然该方法可以处理连接组的小扰动，但较大的扰动或不同的缩放可能会显著降低其性能（图S9）。相反，**纠正结构连接组的已知偏差可以改善模型拟合，这一点在HCP数据上得到了证实，当同侧连接被加强时，模型表现更好**（图S17）。
			- 可以考虑对结构连接进行进一步的人工修正，但也可以采取另一种方法：不将估计的结构连接组作为硬性数据，而只是**作为模型有效连接的软先验**。这种方法已被描述用于由多变量Ornstein-Uhlenbeck过程生成的全脑动力学，使用阈值化的结构连接作为推断有效连接的拓扑掩码（41，42）。甚至可以在没有任何先验解剖约束的情况下推断模型连接，正如中尺度个体化神经动力学（MINDy）方法所展示的那样，该方法依赖于一个简单的单方程神经质量模型（17）。
		- #### *Coupling via the observed variable*
			- 在设计我们的方法时，我们做出的**一个较有争议的选择是假设区域之间通过观察变量耦合**，也就是说，在公式4到6中，g_c ≡ g。这个假设**纯粹是出于实用原因**，因为它允许我们解耦网络问题：有了这个假设，每个区域的网络输入可以预先计算，并在优化过程中保持固定。实际上，这意味着我们是在对n个非耦合区域进行推断，而不是对一个有n个节点的网络进行推断，从而减少了所需的计算资源。
			- 我们用两个简单的事实来证明这个选择的合理性：(i) 它导致了一个可以有效解决的问题，以及 (ii) 设计的方法在合成测试案例中表现得相当好，即使这个假设明显无效。例如，在原始的Hopf模型中，区域通过两个变量耦合，但训练后的模型产生了具有相似相关结构的动力学。同时，我们注意到在两个合成测试案例中网络耦合都减少了，这个假设可能是解释这种减少的一个合理原因。类似地，这可能也是我们无法像其他类似的计算研究那样在相同程度上重现人类fMRI数据的功能连接的部分原因。因此，**设计一种计算效率高的方法来识别完全耦合系统是未来研究的一个重要方向**。
		- #### *Related works on system identification from fMRI signals*
			- **关于大尺度fMRI信号动力学性质的研究结果多样性突显了建模选择的重要性，特别是底层动力学模型和优化成本函数的选择。**Nozari及其同事（43）比较了几类动力学模型在建模全脑静息态fMRI动力学方面的能力，从线性模型到非线性神经质量模型再到深度神经网络模型。他们得出结论，线性自回归模型能达到最佳性能，而更复杂的模型会导致性能下降和计算成本增加。然而，值得注意的是，这些模型是针对单步预测能力进行训练和评估的，目前尚不清楚这些测试模型在其他标准（如静态或时变功能连接或频谱）下的表现如何。
			- Piccinini及其同事（44）使用了结合SINDy类方法（9）的全脑动力学网络模型框架。他们用灵活的多项式形式表示2D神经质量模型，并优化其系数，以达到模拟和实证功能连接的最佳匹配。他们的最佳模型展现了一系列局部动力学，其中大多数具有单个固定点，要么是稳定固定点，要么是极限环，但具有三个或五个固定点的配置也很常见。然而，从报告的结果中很难确定这些模型在除了评估的功能连接标准之外的其他方面与原始数据的匹配程度如何。
			- 将我们的结果与Koppe及其同事（16）的结果进行比较也很有启发性。尽管他们使用了概念上类似的从fMRI时间序列进行系统识别的方法，但在底层动力系统的性质方面得出了相当不同的结果。使用**分段线性递归神经网络**，作者重构了生成fMRI时间序列的动力系统。他们研究了基于任务的fMRI，并独立分析了每个感兴趣区域。他们在推断的系统中发现了丰富的非线性动力学，包括多个时间尺度上的极限环、多稳定性或混沌吸引子，**这与我们的单固定点系统形成鲜明对比**。
			- 我们推测造成这种差异的主要原因有三个。首先是**数据源本身：基于任务的fMRI与我们的静息态fMRI相比。**与静息态fMRI不同，任务设置在任务时间尺度上引入了脑动力学的变化，我们假设这些变化随后反映在任务时间尺度上的状态空间组织和动力学结构中。第二个原因是**所使用的fMRI预处理：与我们不同，Koppe及其同事（16）对用于系统识别的fMRI信号进行了平滑处理。**这看似是一个微小的差异，但却在平滑窗口的短时间尺度上引入了可预测性，这可能导致倾向于通过复杂的确定性动力学而非噪声波动来解释。换句话说，不对时间序列进行平滑处理使得我们的方法需要模拟一个额外的噪声源，而由于这也可以在系统噪声层面上完成，这种预处理选择可能会导致成本函数景观中噪声固定点动力学吸引基础的扩大，使得更复杂的动力学体制更难被发现。**最后，差异可能是由系统识别方法的微妙先验（有意或无意）造成的。**考虑足够复杂的观察动力学，由高维确定性系统模型和低维随机系统模型拟合。虽然前者可能试图用复杂的混沌动力学来解释观察到的动力学，但后者可能依赖于噪声动力学，因为它没有其他可用的选择。然而，高维随机系统模型可能会用确定性混沌动力学或随机噪声，或介于两者之间的任何形式来拟合数据，这取决于方法的有意和无意先验。最终重要的是原始信号重构的质量，这需要对推断出的模型进行仔细的基准测试。
		- #### *Cortical gradients in large-scale brain modeling*
			- 近年来，人类大脑皮层的结构、连接、基因表达和功能梯度引起了相当大的兴趣（45，46），几项建模研究探讨了它们在大尺度脑动力学中的作用（3-6）。我们的方法与它们共享基于结构连接组的大尺度脑建模的基本原则，但在三个关键点上有所不同：首先，我们**不依赖于任何特定的神经群体模型**；相反，模型是从数据中推导出来的。其次，我们推断的区域参数**不受任何特定参数化的约束**。第三，通过成本函数，我们**直接拟合时间序列**，而不是任何衍生特征，如静态或动态功能连接。
			- 就区域参数的异质性而言，我们的结果与以前的研究相比如何？Demirtaş等人（3）使用嵌入在全脑网络中的双群体神经质量模型。他们用近似髓鞘含量的T1w/T2w比率参数化神经质量参数，并优化模型参数以获得最佳功能连接拟合。他们发现，遵循T1w/T2w梯度的异质性比均质模型或随机替代模型改善了拟合效果。Wang等人（6）在网络中使用了一个单方程神经质量模型，其参数被自由优化以再次拟合功能连接矩阵。他们发现最优参数与静息态功能连接（RSFC）的第一主梯度和T1w/T2w图相关。此外，最优回归连接强度与神经元密度图相关。在此基础上，Kong等人（4）用T1w/T2w图和RSFC梯度参数化同一模型，以拟合不仅静态而且动态的功能连接。为了达到这个目标，两种图的参数化都是必要的。这些结论与我们的结果大体一致：第一个推断参数与T1w/T2w图、RSFC梯度和神经元密度相关，尽管关系不那么强，特别是对于RSFC梯度（在我们的情况下R²=0.07）。
			- 然而，Kong等人（4）也注意到他们的最优区域参数与基因表达梯度强烈相关，特别是与2413个脑特异性基因表达图的第一主成分。这是我们的研究强烈支持的关系，因为第一个推断参数与基因表达空间图的第一主成分强烈相关（R²=0.47）。此外，Deco等人（5）研究了基因表达在全脑动力学中的作用。他们比较了神经质量模型用从基因表达获得的兴奋抑制比（E:I）、基因表达的第一主成分和T1w/T2w比率参数化，以及使用均质模型时的拟合优度。E:I情况下拟合效果最好，其次是其他异质模型，然后是均质模型。本研究不支持这一结果，因为EI图与推断参数只有微弱相关。
			- 我们选择使用Desikan-Killiany皮层分区（20）进行分析，主要是为了与相关研究（4-6）保持一致。众所周知，大脑图谱的选择可能会影响神经科学研究的结果（47）。因此，未来应用所提出的框架可能不仅会受益于基于解剖学的分区（如Desikan-Killiany），还会受益于多模态（29）或细胞构筑（48）分区的分析，这些分区应该能更好地反映底层的结构组织。
		- #### *Inferring subject-specific parameters*
			- 将我们提出的方法应用于静息态fMRI数据时，发现**受试者特定参数存在收敛问题**（图S10）；因此，我们在主要分析中只使用了区域特定参数。这种失败的确切原因尚不完全清楚；然而，有几个选项可能在未来的工作中改善这种情况。
			- 在变分自编码器（VAE）的框架下，一个选项是按照所谓的β-VAE方法，增加成本函数中先验和近似后验之间的Kullback-Leibler散度惩罚。β-VAE（49）最初是为了无监督发现解耦表示而提出的，它通过一个可调节的超参数β来约束潜在空间的容量，并鼓励更紧密地遵循先验，但代价是重构质量的降低。自提出以来，这种方法的性能和解耦的精确定义受到了质疑（50，51）。然而，在我们的情况下，它提供了一种直接的方式来获得行为更好的近似后验分布，尽管代价是需要启发式地调整一个额外的参数。
			- 另一个选项源于这样一个猜想：失败是由于在生成模型中强加了一个特定的潜在空间结构，而这个结构在推断模型中没有得到适当的反映。在这里，可以从分层VAE的文献中获得灵感（52-54）。在这些工作中，通过将潜在空间z = {z1, ..., zn}分区并将数据x的近似后验因子化为q(z∣x) = ∏i q(zi∣z<i, x)，引入了潜在空间的特定结构，从而增加了模型的灵活性。沿着类似的思路修改我们的推断模型可能会纠正所观察到的问题。
		- #### *Outlook on the role of dynamically relevant parameters*
			- 在神经退行性疾病（55）和正常衰老过程中（56），静息状态下的大脑大尺度动力学会发生改变。有许多可能影响大尺度动力学的区域性参数可以通过活体或尸检测量，例如细胞密度、细胞类型组成、局部连接结构、与皮层下结构的连接或受体密度等，这里仅列举几例。但哪些参数实际上与大尺度脑动力学相关，它们又是如何影响的呢？**构建包含所有可能参数并允许我们研究其作用的自下而上的机制模型是不可行的，这是因为人脑的复杂性，其动力学跨越多个时间和空间尺度，即使参数被精确测量也是如此**（[Big data and the industrialization of neuroscience: A safe roadmap for understanding the brain? | Science](https://www.science.org/doi/abs/10.1126/science.aan8866)）。
			- 相反，我们的方法从相反的方向追求这种理解。我们使用摊销推断框架来学习驱动动力学的动力系统，同时也学习跨区域和受试者变化的参数。由于这些参数是以无监督的方式从功能数据中推断出来的，它们在构建上就是与大尺度动力学相关的参数。这与机制模型形成对比，机制模型的参数虽然存在于模型公式中，但不一定影响观察到的大尺度动力学，因此无法从功能数据中识别。鉴于推断模型的抽象性质，这些动力学相关参数的机制意义并不明显，但它们仍然提供了衡量脑区和不同受试者相似性的度量，并且可以通过训练好的模型研究它们对动力学的影响。此外，给定足够大的数据集，动力学相关参数可能与测量的量（或它们的组合）联系起来。如果动力学相关参数在疾病不同阶段之间存在差异，这种联系可能为了解神经退行性疾病的起源提供洞见。
			- 动力学相关参数与可测量量之间的联系可以从预先存在的患者群体中估计，然后仅应用于单个受试者。如果测量在临床环境中难以进行、成本高昂或不可能进行（例如从尸检研究中估计的细胞类型组成），这种方法就很有优势；在这种情况下，可以从易于获得的静息态fMRI中估计动力学相关参数，然后使用已知的联系进行映射。因此，这种方法为一方面利用大规模神经影像数据库（如HCP（19）或UK Biobank（58）），另一方面利用详细的细胞构筑（27，48）或遗传（30）脑图谱开辟了新的可能性。
-
- ## METHODS
	- ### Structural connectomes
		-
	- ### Resting-state fMRI data
		-
	- ### Amortized variational inference for networks of nonlinear dynamical systems
		- #### *Generative dynamical system*
			-
		- #### *Evidence lower bound*
			-
	- ### Decoder or the observation model
		- #### *Prior on the system states*
			-
		- #### *Prior on the parameters*
			-
		- #### *Prior on the external input*
			-
		- #### *Approximate posteriors*
			-
	- ### Optimization
		-
	- ### Whole-brain network models for simulated datasets
		- #### *Hopf bifurcation model*
			-
		- #### *Parametric mean field model*
			-
	- ### Relation of regional parameters and regional features from individual and external data
		- #### *Features from individual data*
			-
		- #### *Features from external data*
			-
		- #### *Multivariate linear regression*
			-
	- ### Analysis of the inferred dynamical systems
		-